# Testes do EAÃ­ Gateway

Este diretÃ³rio contÃ©m testes abrangentes para verificar se o sistema estÃ¡ funcionando corretamente.

## ğŸ“‹ Estrutura dos Testes

### ğŸ§ª SuÃ­tes de Teste

1. **Message Formatter Tests** (`test_message_formatter.py`)
   - Testa formataÃ§Ã£o de mensagens para WhatsApp
   - Verifica conversÃ£o Markdown â†’ WhatsApp  
   - Testa compatibilidade com diferentes formatos (Google, Letta, LangChain)
   - Verifica preservaÃ§Ã£o de conteÃºdo

2. **Event Loop Fixes Tests** (`test_event_loop_fixes.py`)
   - Testa correÃ§Ãµes para "Event loop is closed"
   - Verifica funcionamento em diferentes cenÃ¡rios
   - Testa concorrÃªncia e performance
   - Verifica propagaÃ§Ã£o de exceÃ§Ãµes

3. **Provider Integration Tests** (`test_providers_integration.py`)
   - Testa integraÃ§Ã£o com Letta service
   - Testa integraÃ§Ã£o com Google Agent Engine
   - Verifica Provider Factory
   - Testa tratamento de erros

## ğŸš€ Como Executar

### ExecuÃ§Ã£o Simples

```bash
# Executar todos os testes
just test

# Ou manualmente:
uv run python tests/run_all_tests.py
```

### OpÃ§Ãµes AvanÃ§adas

```bash
# Executar apenas testes rÃ¡pidos (sem integraÃ§Ã£o)
uv run python tests/run_all_tests.py --quick

# Pular testes de integraÃ§Ã£o
uv run python tests/run_all_tests.py --skip-integration

# Continuar mesmo com erros
uv run python tests/run_all_tests.py --continue-on-error

# Modo verboso
uv run python tests/run_all_tests.py --verbose

# Ajuda
uv run python tests/run_all_tests.py --help
```

### ExecuÃ§Ã£o Individual

```bash
# Testar apenas formataÃ§Ã£o de mensagens
uv run python tests/test_message_formatter.py

# Testar apenas event loop fixes
uv run python tests/test_event_loop_fixes.py

# Testar apenas integraÃ§Ã£o
uv run python tests/test_providers_integration.py
```

## ğŸ¯ Quando Executar

### Durante Desenvolvimento
- Execute `just test --quick` antes de fazer commits
- Execute testes especÃ­ficos quando modificar componentes relacionados

### VerificaÃ§Ã£o Completa
- Execute `just test` apÃ³s mudanÃ§as significativas
- Execute antes de fazer deploy para produÃ§Ã£o
- Execute periodicamente para verificar saÃºde do sistema

### Monitoramento
- Execute testes de integraÃ§Ã£o para verificar conectividade com APIs externas
- Use em scripts de monitoramento/health check

## ğŸ“Š Interpretando Resultados

### âœ… Sucesso
```
ğŸ‰ TODOS OS TESTES PASSARAM!
   O sistema estÃ¡ funcionando corretamente.
```

### âŒ Falha
```
ğŸ’¥ ALGUNS TESTES FALHARAM!
   Verifique os logs acima para detalhes dos problemas.
```

### âš ï¸ Falhas Esperadas
- **Testes de IntegraÃ§Ã£o**: Podem falhar se APIs externas estiverem indisponÃ­veis
- **Testes de Network**: Podem falhar em ambientes sem internet
- **Testes de Auth**: Podem falhar se credenciais nÃ£o estiverem configuradas

## ğŸ”§ SoluÃ§Ã£o de Problemas

### Erros Comuns

1. **Import Errors**
   ```bash
   # Verificar se estÃ¡ no diretÃ³rio correto
   cd /path/to/app-eai-agent-gateway
   
   # Verificar se dependÃªncias estÃ£o instaladas
   uv sync
   ```

2. **API Connection Errors**
   ```bash
   # Verificar variÃ¡veis de ambiente
   cat .env
   
   # Verificar conectividade
   just health
   ```

3. **Redis Errors**
   ```bash
   # Verificar se Redis estÃ¡ rodando
   just test-services
   ```

### Ambiente de Desenvolvimento

Para ambiente de desenvolvimento, vocÃª pode:

```bash
# Rodar apenas testes que nÃ£o dependem de APIs externas
uv run python tests/run_all_tests.py --skip-integration

# Ou usar modo rÃ¡pido
just test --quick
```

## ğŸ“ˆ MÃ©tricas

Os testes fornecem mÃ©tricas sobre:
- â±ï¸ **Tempo de execuÃ§Ã£o** - Performance dos componentes
- ğŸ¯ **Taxa de sucesso** - Confiabilidade do sistema  
- ğŸ”§ **Coverage** - Quais componentes estÃ£o sendo testados
- ğŸ“Š **TendÃªncias** - Compare execuÃ§Ãµes ao longo do tempo

## ğŸ›¡ï¸ SeguranÃ§a

Os testes sÃ£o projetados para:
- âœ… **NÃ£o expor dados sensÃ­veis** nos logs
- âœ… **Usar dados de teste** em vez de dados reais
- âœ… **Limpar dados** criados durante os testes
- âœ… **Respeitar rate limits** das APIs externas

## ğŸ¤ Contribuindo

Ao adicionar novos recursos:

1. **Adicione testes** para novas funcionalidades
2. **Atualize testes existentes** se necessÃ¡rio
3. **Execute todos os testes** antes de fazer PR
4. **Documente casos especiais** nos comentÃ¡rios do cÃ³digo

### Template para Novos Testes

```python
def test_nova_funcionalidade():
    """Testa nova funcionalidade X"""
    print("ğŸ§ª Testando nova funcionalidade...")
    
    try:
        # Arrange
        # ...
        
        # Act
        # ...
        
        # Assert
        assert resultado_esperado, "Mensagem de erro clara"
        
        print("âœ… Nova funcionalidade OK")
        return True
        
    except Exception as e:
        print(f"âŒ Erro na nova funcionalidade: {e}")
        traceback.print_exc()
        return False
```